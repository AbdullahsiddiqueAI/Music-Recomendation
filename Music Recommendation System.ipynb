{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('songdata.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165df3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=5000).drop('link', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eee439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6bb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .) it mwans itwill rplce thething \\w which are notwords and and \\s means white space and then \\n will also be replce by space .\n",
    "df['text'] = df['text'].str.lower().replace(r'[^\\w\\s]','').replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b8361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3260a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenization(txt):\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    stemming = [stemmer.stem(w) for w in tokens]\n",
    "    return \" \".join(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36974948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ad57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .)the blw stop_words will be removed by auto by this tfidf.\n",
    "tfidvector = TfidfVectorizer(analyzer='word',stop_words='english')\n",
    "matrix = tfidvector.fit_transform(df['text'])\n",
    "similarity = cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efd00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d080eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['song']==''].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5093cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(similarity[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033cceef",
   "metadata": {},
   "source": [
    "# recommedation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse=True: This argument indicates that the sorting order should be reversed, meaning the largest values will come first after sorting.\n",
    "\n",
    "# key=lambda x: x[1]: This argument specifies a custom sorting key. In this case, it's a lambda function that takes an element x (which is a tuple containing an index and a similarity value) and returns the second element of the tuple (x[1]), which represents the similarity value. This means that the sorting will be done based on the similarity values.\n",
    "def recommendation(song_df):\n",
    "    idx = df[df['song'] == song_df].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[idx])),reverse=True,key=lambda x:x[1])\n",
    "    \n",
    "    songs = []\n",
    "    for m_id in distances[1:21]:\n",
    "        # print(\"hello\")\n",
    "        # print(m_id)\n",
    "        songs.append(df.iloc[m_id[0]].song)\n",
    "        \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842ff231",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation('Alma Mater')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b3388",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba04293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(similarity,open('similarity.pkl','wb'))\n",
    "pickle.dump(df,open('df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56a437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
